{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e3790d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 734 files for validation.\n",
      "Epoch 1/3\n",
      "92/92 [==============================] - 154s 2s/step - loss: 0.7368 - accuracy: 0.7698 - val_loss: 0.4181 - val_accuracy: 0.8529\n",
      "Epoch 2/3\n",
      "92/92 [==============================] - 158s 2s/step - loss: 0.2936 - accuracy: 0.8965 - val_loss: 0.3558 - val_accuracy: 0.8665\n",
      "Epoch 3/3\n",
      "92/92 [==============================] - 166s 2s/step - loss: 0.1722 - accuracy: 0.9404 - val_loss: 0.3608 - val_accuracy: 0.8747\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import pathlib\n",
    "\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "img_height, img_width = 180, 180\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    label_mode='categorical',\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "resnet_model = Sequential()\n",
    "pretrained_model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    input_shape=(180, 180, 3),\n",
    "    pooling='avg',\n",
    "    classes=5,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "resnet_model.add(pretrained_model)\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(512, activation='relu'))\n",
    "resnet_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "epochs = 3\n",
    "resnet_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = resnet_model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n",
    "\n",
    "# 모델 저장\n",
    "resnet_model.save(\"ma.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18e3a8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D022AE1790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D022AE1790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "daisy\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path('C:/Users/hk-10/.keras/datasets/flower_photos')\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "flower = list(data_dir.glob('../flower/*'))\n",
    "PIL.Image.open(str(flower[0]))\n",
    "image=cv2.imread(str(flower[0]))\n",
    "image_resized= cv2.resize(image, (180,180))\n",
    "image=np.expand_dims(image_resized,axis=0)\n",
    "pred=resnet_model.predict(image)\n",
    "output_class=class_names[np.argmax(pred)]\n",
    "print(output_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be562ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 605ms/step\n",
      "daisy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "loaded_model = keras.models.load_model(\"C:/Flobot/ma.h5\")\n",
    "\n",
    "data_dir = Path('C:/Flobot/image')\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "flower = list(data_dir.glob('./*'))\n",
    "PIL.Image.open(str(flower[0]))\n",
    "import cv2\n",
    "image=cv2.imread(str(flower[0]))\n",
    "image_resized= cv2.resize(image, (180,180))\n",
    "image=np.expand_dims(image_resized,axis=0)\n",
    "pred=loaded_model.predict(image)\n",
    "output_class=['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'][np.argmax(pred)]\n",
    "print(output_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
